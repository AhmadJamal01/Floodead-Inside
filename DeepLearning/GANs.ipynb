{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmadJamal01/Floodead-Inside/blob/main/GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhLGHma0LoQM"
      },
      "source": [
        "# GANs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMnEFmx9LrYs"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5febYusnLtvp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xByhvFqQst9"
      },
      "source": [
        "## Read the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WLmtNRoTU9-0"
      },
      "outputs": [],
      "source": [
        "! rm -r gan_images/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxV3chd3QvFL",
        "outputId": "222e844c-98a3-4957-9a7c-4de51e97a393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the path to your zip file in Google Drive\n",
        "zip_path = '/content/drive/MyDrive/dataset.zip'\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/') \n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIHFFlmCL0_A"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FuX2_aceQKTh"
      },
      "outputs": [],
      "source": [
        "# Define the generator architecture\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, img_shape, num_classes):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(num_classes, num_classes)\n",
        "        \n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim + num_classes, 128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.BatchNorm1d(1024, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, int(torch.prod(torch.tensor(img_shape)))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        embedded_labels = self.embedding(labels)\n",
        "        input = torch.cat((z, embedded_labels), dim=1)\n",
        "        img = self.model(input)\n",
        "        img = img.view(img.size(0), *img_shape)\n",
        "        return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqa3o8FML9XH"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZurP3R8aL_sB"
      },
      "outputs": [],
      "source": [
        "# Define the discriminator architecture\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_shape, num_classes):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(num_classes, num_classes)\n",
        "        \n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(int(torch.prod(torch.tensor(img_shape))) + num_classes, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img, labels):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        embedded_labels = self.embedding(labels)\n",
        "        input = torch.cat((img_flat, embedded_labels), dim=1)\n",
        "        validity = self.model(input)\n",
        "        return validity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVwEa9mwNbb0"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4Z49Y85Nfsd",
        "outputId": "8cef4e6e-e42b-4a02-e4e4-606f28bdfae5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f49ba7c0c30>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Speed ups\n",
        "torch.autograd.set_detect_anomaly(False)\n",
        "torch.autograd.profiler.profile(False)\n",
        "torch.autograd.profiler.emit_nvtx(False)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Set device (GPU if available, otherwise CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzElrtBiNtmY"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qnPwAjdrNwHm"
      },
      "outputs": [],
      "source": [
        "# Set parameters\n",
        "latent_dim = 100 # the dimensionality of the input noise vector\n",
        "num_classes = 2  # Number of classes (flooded and non-flooded)\n",
        "img_size = 64\n",
        "img_channels = 3\n",
        "batch_size = 64\n",
        "img_shape = (img_channels, img_size, img_size)\n",
        "num_epochs = 100\n",
        "sample_interval = 15\n",
        "lr = 0.0002\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator(latent_dim, img_shape, num_classes).to(device)\n",
        "discriminator = Discriminator(img_shape, num_classes).to(device)\n",
        "\n",
        "# Define loss function and optimizers\n",
        "adversarial_loss = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnHGOfDhRW2S"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AhGnQ5g1RTsj"
      },
      "outputs": [],
      "source": [
        "# Create directory for generated images\n",
        "os.makedirs('gan_images', exist_ok=True)\n",
        "\n",
        "# Define transformations to be applied to the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.CenterCrop(img_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5] * img_channels, std=[0.5] * img_channels)\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "# Access the extracted files\n",
        "path = '/content/dataset/' \n",
        "dataset = ImageFolder(root=path, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "# train, validation, test = torch.utils.data.random_split(dataset, (0.2, 0.4, 0.4))\n",
        "# dataloader = DataLoader(train, batch_size=batch_size, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oeb9y7kPPRZv"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCRu1nxZ4LfY",
        "outputId": "ef6cdd15-7237-40f7-c0ef-baf1ff95df34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100]\n",
            "Epoch [1/100], Batch [15/15], D_loss: 0.4780, G_loss: 0.6801\n",
            "Saving...\n",
            "Epoch [2/100]\n",
            "Epoch [2/100], Batch [15/15], D_loss: 0.3152, G_loss: 1.0011\n",
            "Saving...\n",
            "Epoch [3/100]\n",
            "Epoch [3/100], Batch [15/15], D_loss: 0.3700, G_loss: 1.0689\n",
            "Saving...\n",
            "Epoch [4/100]\n",
            "Epoch [4/100], Batch [15/15], D_loss: 0.3078, G_loss: 0.9890\n",
            "Saving...\n",
            "Epoch [5/100]\n",
            "Epoch [5/100], Batch [15/15], D_loss: 0.3701, G_loss: 0.8197\n",
            "Saving...\n",
            "Epoch [6/100]\n",
            "Epoch [6/100], Batch [15/15], D_loss: 0.3083, G_loss: 0.9261\n",
            "Saving...\n",
            "Epoch [7/100]\n",
            "Epoch [7/100], Batch [15/15], D_loss: 0.1956, G_loss: 1.3877\n",
            "Saving...\n",
            "Epoch [8/100]\n",
            "Epoch [8/100], Batch [15/15], D_loss: 0.1824, G_loss: 1.5442\n",
            "Saving...\n",
            "Epoch [9/100]\n",
            "Epoch [9/100], Batch [15/15], D_loss: 0.0926, G_loss: 2.1130\n",
            "Saving...\n",
            "Epoch [10/100]\n",
            "Epoch [10/100], Batch [15/15], D_loss: 0.0874, G_loss: 2.1612\n",
            "Saving...\n",
            "Epoch [11/100]\n",
            "Epoch [11/100], Batch [15/15], D_loss: 0.1119, G_loss: 2.0738\n",
            "Saving...\n",
            "Epoch [12/100]\n",
            "Epoch [12/100], Batch [15/15], D_loss: 0.1294, G_loss: 2.3380\n",
            "Saving...\n",
            "Epoch [13/100]\n",
            "Epoch [13/100], Batch [15/15], D_loss: 0.6289, G_loss: 1.3277\n",
            "Saving...\n",
            "Epoch [14/100]\n",
            "Epoch [14/100], Batch [15/15], D_loss: 0.8122, G_loss: 1.1321\n",
            "Saving...\n",
            "Epoch [15/100]\n",
            "Epoch [15/100], Batch [15/15], D_loss: 0.4578, G_loss: 2.0766\n",
            "Saving...\n",
            "Epoch [16/100]\n",
            "Epoch [16/100], Batch [15/15], D_loss: 0.5192, G_loss: 1.0720\n",
            "Saving...\n",
            "Epoch [17/100]\n",
            "Epoch [17/100], Batch [15/15], D_loss: 0.3439, G_loss: 2.0445\n",
            "Saving...\n",
            "Epoch [18/100]\n",
            "Epoch [18/100], Batch [15/15], D_loss: 0.3154, G_loss: 1.9421\n",
            "Saving...\n",
            "Epoch [19/100]\n",
            "Epoch [19/100], Batch [15/15], D_loss: 0.6484, G_loss: 1.7106\n",
            "Saving...\n",
            "Epoch [20/100]\n",
            "Epoch [20/100], Batch [15/15], D_loss: 0.4365, G_loss: 1.1234\n",
            "Saving...\n",
            "Epoch [21/100]\n",
            "Epoch [21/100], Batch [15/15], D_loss: 0.3167, G_loss: 1.5728\n",
            "Saving...\n",
            "Epoch [22/100]\n",
            "Epoch [22/100], Batch [15/15], D_loss: 0.5415, G_loss: 2.7016\n",
            "Saving...\n",
            "Epoch [23/100]\n",
            "Epoch [23/100], Batch [15/15], D_loss: 0.5237, G_loss: 1.3197\n",
            "Saving...\n",
            "Epoch [24/100]\n",
            "Epoch [24/100], Batch [15/15], D_loss: 0.6255, G_loss: 1.4947\n",
            "Saving...\n",
            "Epoch [25/100]\n",
            "Epoch [25/100], Batch [15/15], D_loss: 0.4905, G_loss: 1.3420\n",
            "Saving...\n",
            "Epoch [26/100]\n",
            "Epoch [26/100], Batch [15/15], D_loss: 0.5291, G_loss: 1.6448\n",
            "Saving...\n",
            "Epoch [27/100]\n",
            "Epoch [27/100], Batch [15/15], D_loss: 0.4907, G_loss: 2.2409\n",
            "Saving...\n",
            "Epoch [28/100]\n",
            "Epoch [28/100], Batch [15/15], D_loss: 0.7604, G_loss: 0.9046\n",
            "Saving...\n",
            "Epoch [29/100]\n",
            "Epoch [29/100], Batch [15/15], D_loss: 0.5022, G_loss: 1.3422\n",
            "Saving...\n",
            "Epoch [30/100]\n",
            "Epoch [30/100], Batch [15/15], D_loss: 0.3542, G_loss: 1.4098\n",
            "Saving...\n",
            "Epoch [31/100]\n",
            "Epoch [31/100], Batch [15/15], D_loss: 0.5810, G_loss: 1.8610\n",
            "Saving...\n",
            "Epoch [32/100]\n",
            "Epoch [32/100], Batch [15/15], D_loss: 0.5183, G_loss: 1.1917\n",
            "Saving...\n",
            "Epoch [33/100]\n",
            "Epoch [33/100], Batch [15/15], D_loss: 0.4421, G_loss: 1.8382\n",
            "Saving...\n",
            "Epoch [34/100]\n",
            "Epoch [34/100], Batch [15/15], D_loss: 0.9826, G_loss: 0.9189\n",
            "Saving...\n",
            "Epoch [35/100]\n",
            "Epoch [35/100], Batch [15/15], D_loss: 0.5636, G_loss: 0.9174\n",
            "Saving...\n",
            "Epoch [36/100]\n",
            "Epoch [36/100], Batch [15/15], D_loss: 0.4110, G_loss: 1.8809\n",
            "Saving...\n",
            "Epoch [37/100]\n",
            "Epoch [37/100], Batch [15/15], D_loss: 0.6009, G_loss: 0.8739\n",
            "Saving...\n",
            "Epoch [38/100]\n",
            "Epoch [38/100], Batch [15/15], D_loss: 0.6442, G_loss: 1.3066\n",
            "Saving...\n",
            "Epoch [39/100]\n",
            "Epoch [39/100], Batch [15/15], D_loss: 0.5027, G_loss: 1.6437\n",
            "Saving...\n",
            "Epoch [40/100]\n",
            "Epoch [40/100], Batch [15/15], D_loss: 0.3979, G_loss: 1.3278\n",
            "Saving...\n",
            "Epoch [41/100]\n",
            "Epoch [41/100], Batch [15/15], D_loss: 0.4500, G_loss: 1.1789\n",
            "Saving...\n",
            "Epoch [42/100]\n",
            "Epoch [42/100], Batch [15/15], D_loss: 0.4993, G_loss: 1.7886\n",
            "Saving...\n",
            "Epoch [43/100]\n",
            "Epoch [43/100], Batch [15/15], D_loss: 0.5236, G_loss: 1.3976\n",
            "Saving...\n",
            "Epoch [44/100]\n",
            "Epoch [44/100], Batch [15/15], D_loss: 0.7098, G_loss: 1.5361\n",
            "Saving...\n",
            "Epoch [45/100]\n",
            "Epoch [45/100], Batch [15/15], D_loss: 0.4854, G_loss: 1.6228\n",
            "Saving...\n",
            "Epoch [46/100]\n",
            "Epoch [46/100], Batch [15/15], D_loss: 0.7582, G_loss: 0.7820\n",
            "Saving...\n",
            "Epoch [47/100]\n",
            "Epoch [47/100], Batch [15/15], D_loss: 0.3631, G_loss: 1.8039\n",
            "Saving...\n",
            "Epoch [48/100]\n",
            "Epoch [48/100], Batch [15/15], D_loss: 0.4147, G_loss: 1.4550\n",
            "Saving...\n",
            "Epoch [49/100]\n",
            "Epoch [49/100], Batch [15/15], D_loss: 0.3754, G_loss: 1.4905\n",
            "Saving...\n",
            "Epoch [50/100]\n",
            "Epoch [50/100], Batch [15/15], D_loss: 0.3551, G_loss: 1.2396\n",
            "Saving...\n",
            "Epoch [51/100]\n",
            "Epoch [51/100], Batch [15/15], D_loss: 0.4244, G_loss: 1.3653\n",
            "Saving...\n",
            "Epoch [52/100]\n",
            "Epoch [52/100], Batch [15/15], D_loss: 0.4425, G_loss: 1.7110\n",
            "Saving...\n",
            "Epoch [53/100]\n",
            "Epoch [53/100], Batch [15/15], D_loss: 0.5765, G_loss: 1.4316\n",
            "Saving...\n",
            "Epoch [54/100]\n",
            "Epoch [54/100], Batch [15/15], D_loss: 0.4691, G_loss: 1.1227\n",
            "Saving...\n",
            "Epoch [55/100]\n",
            "Epoch [55/100], Batch [15/15], D_loss: 0.4050, G_loss: 1.4015\n",
            "Saving...\n",
            "Epoch [56/100]\n",
            "Epoch [56/100], Batch [15/15], D_loss: 0.4500, G_loss: 1.4048\n",
            "Saving...\n",
            "Epoch [57/100]\n",
            "Epoch [57/100], Batch [15/15], D_loss: 0.4168, G_loss: 1.8407\n",
            "Saving...\n",
            "Epoch [58/100]\n",
            "Epoch [58/100], Batch [15/15], D_loss: 0.4262, G_loss: 1.4196\n",
            "Saving...\n",
            "Epoch [59/100]\n",
            "Epoch [59/100], Batch [15/15], D_loss: 0.5512, G_loss: 1.4055\n",
            "Saving...\n",
            "Epoch [60/100]\n",
            "Epoch [60/100], Batch [15/15], D_loss: 0.3868, G_loss: 1.3446\n",
            "Saving...\n",
            "Epoch [61/100]\n",
            "Epoch [61/100], Batch [15/15], D_loss: 0.5298, G_loss: 2.2280\n",
            "Saving...\n",
            "Epoch [62/100]\n",
            "Epoch [62/100], Batch [15/15], D_loss: 0.4714, G_loss: 1.6003\n",
            "Saving...\n",
            "Epoch [63/100]\n",
            "Epoch [63/100], Batch [15/15], D_loss: 0.5072, G_loss: 1.2999\n",
            "Saving...\n",
            "Epoch [64/100]\n",
            "Epoch [64/100], Batch [15/15], D_loss: 0.5142, G_loss: 1.3468\n",
            "Saving...\n",
            "Epoch [65/100]\n",
            "Epoch [65/100], Batch [15/15], D_loss: 0.4574, G_loss: 1.2432\n",
            "Saving...\n",
            "Epoch [66/100]\n",
            "Epoch [66/100], Batch [15/15], D_loss: 0.5162, G_loss: 1.7750\n",
            "Saving...\n",
            "Epoch [67/100]\n",
            "Epoch [67/100], Batch [15/15], D_loss: 0.5003, G_loss: 1.4747\n",
            "Saving...\n",
            "Epoch [68/100]\n",
            "Epoch [68/100], Batch [15/15], D_loss: 0.5049, G_loss: 1.6702\n",
            "Saving...\n",
            "Epoch [69/100]\n",
            "Epoch [69/100], Batch [15/15], D_loss: 0.4819, G_loss: 1.7728\n",
            "Saving...\n",
            "Epoch [70/100]\n",
            "Epoch [70/100], Batch [15/15], D_loss: 0.4267, G_loss: 1.4964\n",
            "Saving...\n",
            "Epoch [71/100]\n",
            "Epoch [71/100], Batch [15/15], D_loss: 0.4407, G_loss: 2.2240\n",
            "Saving...\n",
            "Epoch [72/100]\n",
            "Epoch [72/100], Batch [15/15], D_loss: 0.5399, G_loss: 1.2832\n",
            "Saving...\n",
            "Epoch [73/100]\n",
            "Epoch [73/100], Batch [15/15], D_loss: 0.4729, G_loss: 1.3621\n",
            "Saving...\n",
            "Epoch [74/100]\n",
            "Epoch [74/100], Batch [15/15], D_loss: 0.6815, G_loss: 0.8240\n",
            "Saving...\n",
            "Epoch [75/100]\n",
            "Epoch [75/100], Batch [15/15], D_loss: 0.5593, G_loss: 2.5712\n",
            "Saving...\n",
            "Epoch [76/100]\n",
            "Epoch [76/100], Batch [15/15], D_loss: 0.5407, G_loss: 1.7327\n",
            "Saving...\n",
            "Epoch [77/100]\n",
            "Epoch [77/100], Batch [15/15], D_loss: 0.5142, G_loss: 1.6496\n",
            "Saving...\n",
            "Epoch [78/100]\n",
            "Epoch [78/100], Batch [15/15], D_loss: 0.5508, G_loss: 1.7259\n",
            "Saving...\n",
            "Epoch [79/100]\n",
            "Epoch [79/100], Batch [15/15], D_loss: 0.5252, G_loss: 1.0740\n",
            "Saving...\n",
            "Epoch [80/100]\n",
            "Epoch [80/100], Batch [15/15], D_loss: 0.7069, G_loss: 1.1831\n",
            "Saving...\n",
            "Epoch [81/100]\n",
            "Epoch [81/100], Batch [15/15], D_loss: 0.6540, G_loss: 0.8825\n",
            "Saving...\n",
            "Epoch [82/100]\n",
            "Epoch [82/100], Batch [15/15], D_loss: 0.6762, G_loss: 1.0621\n",
            "Saving...\n",
            "Epoch [83/100]\n",
            "Epoch [83/100], Batch [15/15], D_loss: 0.4561, G_loss: 1.9033\n",
            "Saving...\n",
            "Epoch [84/100]\n",
            "Epoch [84/100], Batch [15/15], D_loss: 0.3675, G_loss: 1.4823\n",
            "Saving...\n",
            "Epoch [85/100]\n",
            "Epoch [85/100], Batch [15/15], D_loss: 0.4834, G_loss: 1.5028\n",
            "Saving...\n",
            "Epoch [86/100]\n",
            "Epoch [86/100], Batch [15/15], D_loss: 0.5918, G_loss: 1.7250\n",
            "Saving...\n",
            "Epoch [87/100]\n",
            "Epoch [87/100], Batch [15/15], D_loss: 0.5356, G_loss: 1.6055\n",
            "Saving...\n",
            "Epoch [88/100]\n",
            "Epoch [88/100], Batch [15/15], D_loss: 0.4766, G_loss: 2.0118\n",
            "Saving...\n",
            "Epoch [89/100]\n",
            "Epoch [89/100], Batch [15/15], D_loss: 0.6307, G_loss: 0.9910\n",
            "Saving...\n",
            "Epoch [90/100]\n",
            "Epoch [90/100], Batch [15/15], D_loss: 0.7187, G_loss: 1.1956\n",
            "Saving...\n",
            "Epoch [91/100]\n",
            "Epoch [91/100], Batch [15/15], D_loss: 0.5733, G_loss: 1.9021\n",
            "Saving...\n",
            "Epoch [92/100]\n",
            "Epoch [92/100], Batch [15/15], D_loss: 0.5574, G_loss: 1.4594\n",
            "Saving...\n",
            "Epoch [93/100]\n",
            "Epoch [93/100], Batch [15/15], D_loss: 0.4845, G_loss: 1.0800\n",
            "Saving...\n",
            "Epoch [94/100]\n",
            "Epoch [94/100], Batch [15/15], D_loss: 0.5527, G_loss: 1.9159\n",
            "Saving...\n",
            "Epoch [95/100]\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "    for i, (imgs, labels) in enumerate(dataloader):\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = torch.ones(imgs.size(0), 1).to(device)\n",
        "        fake = torch.zeros(imgs.size(0), 1).to(device)\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = torch.randn(imgs.size(0), latent_dim).to(device)\n",
        "\n",
        "        # Generate a batch of images\n",
        "        fake_imgs = generator(z, labels)\n",
        "\n",
        "        # Measure discriminator's ability to classify real and fake images\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs, labels), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(fake_imgs.detach(), labels), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = torch.randn(imgs.size(0), latent_dim).to(device)\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = generator(z, labels)\n",
        "\n",
        "        # Measure generator's ability to fool the discriminator\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs, labels), valid)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # Print progress\n",
        "        if (i + 1) % sample_interval == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(dataloader)}], D_loss: {d_loss.item():.4f}, G_loss: {g_loss.item():.4f}\")\n",
        "            # Save generated images\n",
        "            print(\"Saving...\")\n",
        "            save_image(gen_imgs.data, f\"gan_images/{epoch+1}_{i+1}.png\", nrow=5, normalize=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "R3XlM-ojk8tr",
        "outputId": "dd514e69-7672-4e31-c84b-516db1c49afa"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "torch.save(generator.state_dict(), 'generator.pth')\n",
        "torch.save(discriminator.state_dict(), 'discriminator.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EN3FPRGT4kWO"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "generator = Generator(latent_dim, img_shape, num_classes).to(device)\n",
        "discriminator = Discriminator(img_shape, num_classes).to(device)\n",
        "\n",
        "generator.load_state_dict(torch.load('generator.pth'))\n",
        "discriminator.load_state_dict(torch.load('discriminator.pth'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AEG70P74pqx"
      },
      "outputs": [],
      "source": [
        "# Set the model to evaluation mode\n",
        "generator.eval()\n",
        "discriminator.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzdYV9xA4whD"
      },
      "outputs": [],
      "source": [
        "# Generate images using the trained generator:\n",
        "num_images = 10  # Number of images to generate\n",
        "labels = torch.tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1])  # Example labels for generating specific class images\n",
        "z = torch.randn(num_images, latent_dim).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    gen_imgs = generator(z, labels).detach().cpu()\n",
        "\n",
        "# Save or display the generated images\n",
        "for i in range(num_images):\n",
        "    save_image(gen_imgs[i], f\"generated_images/generated_{i}.png\", normalize=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOMDp-dk5Rrc"
      },
      "outputs": [],
      "source": [
        "# Display the Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Rescaling Pixel Values: \n",
        "# Rescales the pixel values of the generated images from the range [-1, 1] to [0, 1]. \n",
        "# This is necessary because the generator outputs images with pixel values in the range [-1, 1] due to the Tanh activation function.\n",
        "generated_imgs = (gen_imgs + 1) / 2.0\n",
        "\n",
        "# Create a grid of images\n",
        "rows = 5\n",
        "cols = 5\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(10, 10))\n",
        "\n",
        "# Iterate over the grid and plot the generated images\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    img = generated_imgs[i]\n",
        "    ax.imshow(img.transpose(1, 2, 0))\n",
        "    ax.axis('off')\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPZ5iDOQS5jilvMGSx0UdhP",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
