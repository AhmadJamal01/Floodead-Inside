{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmadJamal01/Floodead-Inside/blob/main/Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lU65wIk57haw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import lr_scheduler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the dataset"
      ],
      "metadata": {
        "id": "aZmn6TyYyb2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdal > /dev/null"
      ],
      "metadata": {
        "id": "rArTdndiyA4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import gdown\n",
        "# gdown.download(\"https://drive.google.com/uc?id=1och-QmNa3FAiS-wssgzCwISbmpSezIi_\", \"dataset.zip\", quiet=False)\n",
        "# gdown.extractall(\"dataset.zip\")\n",
        "# path = 'dataset/'\n",
        "\n",
        "# gdown.download(\"https://drive.google.com/file/d/1YUbTBFrk9QF0ivR5F640G3dhCMC3XQUZ/view?usp=sharing\", \"dataset.zip\", quiet=False, fuzzy=True)"
      ],
      "metadata": {
        "id": "a7XRy_rtyFEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the path to your zip file in Google Drive\n",
        "# zip_path = '/content/drive/MyDrive/dataset.zip'\n",
        "zip_path = '/content/drive/MyDrive/SatelliteImageryProject/dataset.zip'\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')  # Specify the extraction path\n",
        "\n",
        "# Access the extracted files\n",
        "path = '/content/dataset/'  # Update with your extraction path\n",
        "# You can now work with the extracted files in the extracted_files_path directory\n"
      ],
      "metadata": {
        "id": "6VnV8Tvt7zX-",
        "outputId": "6e0e0eee-a296-48d6-88cb-4d410e4dc2b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the data"
      ],
      "metadata": {
        "id": "RgAykbJbytzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data transformations for the training set\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# Define the data transformations for the validation and test sets\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# Load the dataset without applying any transformations\n",
        "dataset = torchvision.datasets.ImageFolder(root=path)\n",
        "\n",
        "# Split the dataset into train and test\n",
        "TRAIN_SIZE = 0.8\n",
        "VALIDATION_SIZE = 0.1\n",
        "\n",
        "train_size = int(TRAIN_SIZE * len(dataset))\n",
        "validation_size = int(VALIDATION_SIZE * len(dataset))\n",
        "test_size = len(dataset) - (train_size + validation_size)\n",
        "train_data, validation_data, test_data = torch.utils.data.random_split(dataset, (train_size, validation_size, test_size))\n",
        "\n",
        "# Apply the data transformations to each dataset\n",
        "train_data.dataset.transform = train_transforms\n",
        "validation_data.dataset.transform = val_test_transforms\n",
        "test_data.dataset.transform = val_test_transforms\n",
        "\n",
        "batch_size = 32\n",
        "trainLoader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "validationLoader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "testLoader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "ZevE8yKh8uDO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Device"
      ],
      "metadata": {
        "id": "AerkruVB8J6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Availabe device for training is: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwYdp7KR8NcC",
        "outputId": "b3412692-6dce-4f1a-a579-7d7dcfd277d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Availabe device for training is: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speedups"
      ],
      "metadata": {
        "id": "MiBYW5nqtYR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.autograd.set_detect_anomaly(False)\n",
        "torch.autograd.profiler.profile(False)\n",
        "torch.autograd.profiler.emit_nvtx(False)\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "HsNT4jTGtWKB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ],
      "metadata": {
        "id": "wpqTzs1Ry4ux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet18"
      ],
      "metadata": {
        "id": "B40QUlXjgiMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define ResNet model \n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "#  Modify the first layer to be able to handle our data\n",
        "model.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "# Modify the last layer to work with two classes\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 2)\n",
        "\n",
        "# Move the model to GPU if possible\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function, optimizer, and lr schehduler\n",
        "# criterion: The loss function used for optimization.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer: The optimizer to update the model's parameters.\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "# step_lr_scheduler: The learning rate scheduler for adjusting the learning rate during training.\n",
        "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n"
      ],
      "metadata": {
        "id": "dRTZBJdo84PR",
        "outputId": "bfb137ba-91a2-4a61-8ed2-5126045452e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DenseNet"
      ],
      "metadata": {
        "id": "FLmmBKMBgkAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define DensNet model \n",
        "model = models.densenet121(pretrained=True)\n",
        "\n",
        "# Modify the first layer to be able to handle our data\n",
        "model.features.conv0 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "# Modify the last layer to work with two classes\n",
        "model.classifier = nn.Linear(model.classifier.in_features, 2)\n",
        "\n",
        "# Move the model to GPU if possible\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function, optimizer, and lr schehduler\n",
        "# criterion: The loss function used for optimization.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer: The optimizer to update the model's parameters.\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "# step_lr_scheduler: The learning rate scheduler for adjusting the learning rate during training.\n",
        "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "GGmEpy04glmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resenet50"
      ],
      "metadata": {
        "id": "I-Ku6mYlnTqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define ResNet model \n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Modify the last layer to work with two classes\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 2)\n",
        "\n",
        "# Move the model to GPU if possible\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function, optimizer, and lr scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl68F1cynVu4",
        "outputId": "fd009158-94ec-44c0-b74e-d78b2a8b0b15"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Enhancement "
      ],
      "metadata": {
        "id": "C0_KeWHH6lCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropout\n",
        "Dropout is a regularization technique that can help prevent overfitting by randomly disabling neurons during training. It can be added after fully connected layers to reduce the model's reliance on specific features and encourage better generalization."
      ],
      "metadata": {
        "id": "cFK3W61W60wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Dropout after the last fully connected layer\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, 2)\n",
        ")\n",
        "# use model.classifier for the densenet\n"
      ],
      "metadata": {
        "id": "xRvdF9kX65DE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "nLdO2X4OzB7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import copy\n",
        "\n",
        "def train_model(model, trainloader, validationloader, device, criterion, optimizer, step_lr_scheduler, epochs):\n",
        "    '''\n",
        "    This code is designed to train a model, track its performance during training, and return the best model along with the loss and accuracy values.\n",
        "    '''\n",
        "    try:\n",
        "        model = model.to(device)\n",
        "\n",
        "        since = time.time()\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        best_acc = 0.0\n",
        "\n",
        "        train_acc = []\n",
        "        train_loss = []\n",
        "        valid_acc = []\n",
        "        valid_loss = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print('-' * 80)\n",
        "            print(f'Epoch {epoch + 1}/{epochs}')\n",
        "\n",
        "            for phase in ['train', 'valid']:\n",
        "                if phase == 'train':\n",
        "                    model.train()\n",
        "                    dataloader = trainloader\n",
        "                    dataset_size = len(trainloader.dataset)\n",
        "                else:\n",
        "                    model.eval()\n",
        "                    dataloader = validationloader\n",
        "                    dataset_size = len(validationloader.dataset)\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                for data in dataloader:\n",
        "                    # Get the training data items of the current batch\n",
        "                    inputs, labels = data\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        # Forward pass\n",
        "                        outputs = model(inputs)\n",
        "                        # Predict the current batch\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        # Compute loss\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        if phase == 'train':\n",
        "                            # Set the gradients of all the parameters of the model to zero\n",
        "                            optimizer.zero_grad()\n",
        "                            # Backward propagation to calculate the gradient\n",
        "                            loss.backward()\n",
        "                            # Update the NN weights by using the gradient\n",
        "                            optimizer.step()\n",
        "\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    step_lr_scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / dataset_size\n",
        "                epoch_acc = running_corrects.double() / dataset_size\n",
        "\n",
        "                if phase == 'valid':\n",
        "                    valid_acc.append(epoch_acc)\n",
        "                    valid_loss.append(epoch_loss)\n",
        "                else:\n",
        "                    train_acc.append(epoch_acc)\n",
        "                    train_loss.append(epoch_loss)\n",
        "\n",
        "                print('{} loss: {:.4f} --------------- {} accuracy: {:.4f}'.format(phase, epoch_loss, phase, epoch_acc))\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == 'valid' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('-' * 80)\n",
        "        print('Training completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "        print('Best validation accuracy: {:4f}'.format(best_acc))\n",
        "\n",
        "        # load best model weights\n",
        "        print('Loading final model weights...')\n",
        "        model.load_state_dict(best_model_wts)\n",
        "        return model, train_loss, train_acc, valid_loss, valid_acc\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during training: {str(e)}\")\n",
        "        return None, [], [], [], []\n"
      ],
      "metadata": {
        "id": "I3hgpYOs6v0S"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, train_loss, train_acc, valid_loss, valid_acc = train_model(model, trainLoader, validationLoader, device, criterion, optimizer, step_lr_scheduler, epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42zWQDkt6pIQ",
        "outputId": "63f29be2-e27e-47e5-8f83-634fa06ead7f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Epoch 1/15\n",
            "train loss: 0.5645 --------------- train accuracy: 0.7083\n",
            "valid loss: 0.3970 --------------- valid accuracy: 0.8696\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 2/15\n",
            "train loss: 0.2952 --------------- train accuracy: 0.8874\n",
            "valid loss: 0.2941 --------------- valid accuracy: 0.9022\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 3/15\n",
            "train loss: 0.2007 --------------- train accuracy: 0.9281\n",
            "valid loss: 0.2451 --------------- valid accuracy: 0.9348\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 4/15\n",
            "train loss: 0.1344 --------------- train accuracy: 0.9539\n",
            "valid loss: 0.1719 --------------- valid accuracy: 0.9457\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 5/15\n",
            "train loss: 0.1329 --------------- train accuracy: 0.9498\n",
            "valid loss: 0.2111 --------------- valid accuracy: 0.9348\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 6/15\n",
            "train loss: 0.0642 --------------- train accuracy: 0.9783\n",
            "valid loss: 0.2076 --------------- valid accuracy: 0.9457\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 7/15\n",
            "train loss: 0.0616 --------------- train accuracy: 0.9810\n",
            "valid loss: 0.1875 --------------- valid accuracy: 0.9565\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 8/15\n",
            "train loss: 0.0272 --------------- train accuracy: 0.9973\n",
            "valid loss: 0.1870 --------------- valid accuracy: 0.9348\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 9/15\n",
            "train loss: 0.0242 --------------- train accuracy: 0.9973\n",
            "valid loss: 0.1799 --------------- valid accuracy: 0.9457\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 10/15\n",
            "train loss: 0.0197 --------------- train accuracy: 1.0000\n",
            "valid loss: 0.1814 --------------- valid accuracy: 0.9565\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 11/15\n",
            "train loss: 0.0280 --------------- train accuracy: 0.9946\n",
            "valid loss: 0.1867 --------------- valid accuracy: 0.9457\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 12/15\n",
            "train loss: 0.0263 --------------- train accuracy: 0.9959\n",
            "valid loss: 0.2066 --------------- valid accuracy: 0.9348\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 13/15\n",
            "train loss: 0.0214 --------------- train accuracy: 0.9959\n",
            "valid loss: 0.1808 --------------- valid accuracy: 0.9457\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 14/15\n",
            "train loss: 0.0207 --------------- train accuracy: 0.9973\n",
            "valid loss: 0.1892 --------------- valid accuracy: 0.9239\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 15/15\n",
            "train loss: 0.0239 --------------- train accuracy: 0.9959\n",
            "valid loss: 0.1783 --------------- valid accuracy: 0.9457\n",
            "--------------------------------------------------------------------------------\n",
            "Training completed in 21m 58s\n",
            "Best validation accuracy: 0.956522\n",
            "Loading final model weights...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "Cxb3uKWfzHuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, dataloader, device):\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            \n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            \n",
        "    return np.asarray(y_pred), np.asarray(y_true)"
      ],
      "metadata": {
        "id": "v8j754lVfBY7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Test the model on the test dataset\n",
        "y_pred, y_true = predict(model, testLoader, device)\n",
        "        \n",
        "# Evalaution        \n",
        "# Calculate accuracy and F1 score\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
        "print('F1 Score: {:.2f}'.format(f1))\n",
        "\n",
        "# Show the whole report\n",
        "classification_report = classification_report(y_true, y_pred)\n",
        "print(classification_report)\n"
      ],
      "metadata": {
        "id": "sWtfEoTz878B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cae8f9a-df98-4b0f-aabf-ad1784e95c43"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 93.55%\n",
            "F1 Score: 0.93\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.90      0.94        49\n",
            "           1       0.90      0.98      0.93        44\n",
            "\n",
            "    accuracy                           0.94        93\n",
            "   macro avg       0.94      0.94      0.94        93\n",
            "weighted avg       0.94      0.94      0.94        93\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine Train and Val datasets"
      ],
      "metadata": {
        "id": "XfZZf4KpNXAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import ConcatDataset\n",
        "\n",
        "# Combine the training and validation data into a single dataset\n",
        "train_val_data = ConcatDataset([train_data, validation_data])\n",
        "\n",
        "# Create a DataLoader for the combined dataset\n",
        "train_val_loader = torch.utils.data.DataLoader(train_val_data, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "VFljRrG4NWwh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_val_data.cummulative_sizes)"
      ],
      "metadata": {
        "id": "xSwQ6STePGBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5-Fold Cross Validation"
      ],
      "metadata": {
        "id": "a5XRKSoXMJZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Define the number of folds\n",
        "k = 3\n",
        "\n",
        "# Create a KFold object\n",
        "kfold = KFold(n_splits=k, shuffle=True)\n",
        "\n",
        "# Initialize a variable to track the total validation accuracy\n",
        "total_valid_acc = 0.0\n",
        "\n",
        "# Save the initial state of the model\n",
        "initial_model_state = copy.deepcopy(model.state_dict())\n",
        "\n",
        "# Split the training data into k folds\n",
        "for fold, (train_index, validation_index) in enumerate(kfold.split(train_data)):\n",
        "    print(f'Fold {fold + 1}/{k}')\n",
        "\n",
        "    # Reset the model to its initial state\n",
        "    model.load_state_dict(initial_model_state)\n",
        "    \n",
        "    # Create a Subset object for the current train and validation sets\n",
        "    train_subset = torch.utils.data.Subset(train_val_data, train_index)\n",
        "    validation_subset = torch.utils.data.Subset(train_val_data, validation_index)\n",
        "    \n",
        "    # Create DataLoaders for the current train and validation sets\n",
        "    trainLoader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    validationLoader = torch.utils.data.DataLoader(validation_subset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    \n",
        "    # Train the model using the current train and validation sets\n",
        "    model, train_loss, train_acc, valid_loss, valid_acc = train_model(model, trainLoader, validationLoader, device, criterion, optimizer, step_lr_scheduler, epochs=15)\n",
        "\n",
        "    # Update the total validation accuracy\n",
        "    total_valid_acc += valid_acc[-1]\n",
        "\n",
        "# Compute the average validation accuracy over the k folds\n",
        "avg_valid_acc = total_valid_acc / k\n",
        "print(f'Average validation accuracy: {avg_valid_acc:.4f}')"
      ],
      "metadata": {
        "id": "scO52ocIMJG9",
        "outputId": "6fe3d41b-e554-48b2-822d-d67e3dc0e933",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/3\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 1/15\n",
            "train loss: 0.5436 --------------- train accuracy: 0.7189\n",
            "valid loss: 0.5107 --------------- valid accuracy: 0.7439\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 2/15\n",
            "train loss: 0.3330 --------------- train accuracy: 0.8635\n",
            "valid loss: 0.3690 --------------- valid accuracy: 0.8455\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 3/15\n",
            "train loss: 0.2456 --------------- train accuracy: 0.9043\n",
            "valid loss: 0.2880 --------------- valid accuracy: 0.8984\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 4/15\n",
            "train loss: 0.1481 --------------- train accuracy: 0.9552\n",
            "valid loss: 0.2639 --------------- valid accuracy: 0.8984\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 5/15\n",
            "train loss: 0.0982 --------------- train accuracy: 0.9735\n",
            "valid loss: 0.2295 --------------- valid accuracy: 0.9065\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 6/15\n",
            "train loss: 0.0696 --------------- train accuracy: 0.9817\n",
            "valid loss: 0.2237 --------------- valid accuracy: 0.9146\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 7/15\n",
            "train loss: 0.0459 --------------- train accuracy: 0.9980\n",
            "valid loss: 0.2268 --------------- valid accuracy: 0.9146\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 8/15\n",
            "train loss: 0.0382 --------------- train accuracy: 0.9959\n",
            "valid loss: 0.2197 --------------- valid accuracy: 0.9106\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 9/15\n",
            "train loss: 0.0325 --------------- train accuracy: 1.0000\n",
            "valid loss: 0.2129 --------------- valid accuracy: 0.9187\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 10/15\n",
            "train loss: 0.0324 --------------- train accuracy: 1.0000\n",
            "valid loss: 0.2090 --------------- valid accuracy: 0.9268\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 11/15\n",
            "train loss: 0.0233 --------------- train accuracy: 1.0000\n",
            "valid loss: 0.2101 --------------- valid accuracy: 0.9268\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 12/15\n",
            "train loss: 0.0314 --------------- train accuracy: 0.9980\n",
            "valid loss: 0.2139 --------------- valid accuracy: 0.9146\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 13/15\n",
            "train loss: 0.0344 --------------- train accuracy: 0.9959\n",
            "valid loss: 0.2058 --------------- valid accuracy: 0.9268\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 14/15\n",
            "train loss: 0.0403 --------------- train accuracy: 0.9939\n",
            "valid loss: 0.2094 --------------- valid accuracy: 0.9309\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 15/15\n",
            "train loss: 0.0221 --------------- train accuracy: 1.0000\n",
            "valid loss: 0.2019 --------------- valid accuracy: 0.9146\n",
            "--------------------------------------------------------------------------------\n",
            "Training completed in 18m 27s\n",
            "Best validation accuracy: 0.930894\n",
            "Loading final model weights...\n",
            "Fold 2/3\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 1/15\n",
            "train loss: 0.6483 --------------- train accuracy: 0.6029\n",
            "valid loss: 0.6576 --------------- valid accuracy: 0.6301\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 2/15\n",
            "train loss: 0.6442 --------------- train accuracy: 0.6334\n",
            "valid loss: 0.6305 --------------- valid accuracy: 0.6382\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 3/15\n",
            "train loss: 0.6400 --------------- train accuracy: 0.6314\n",
            "valid loss: 0.6181 --------------- valid accuracy: 0.6341\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 4/15\n",
            "train loss: 0.6191 --------------- train accuracy: 0.6619\n",
            "valid loss: 0.6090 --------------- valid accuracy: 0.6626\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 5/15\n",
            "train loss: 0.6117 --------------- train accuracy: 0.6701\n",
            "valid loss: 0.6001 --------------- valid accuracy: 0.6545\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 6/15\n",
            "train loss: 0.6059 --------------- train accuracy: 0.6965\n",
            "valid loss: 0.5964 --------------- valid accuracy: 0.6748\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 7/15\n",
            "train loss: 0.5983 --------------- train accuracy: 0.6843\n",
            "valid loss: 0.5990 --------------- valid accuracy: 0.6626\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 8/15\n",
            "train loss: 0.5979 --------------- train accuracy: 0.6782\n",
            "valid loss: 0.5985 --------------- valid accuracy: 0.6504\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 9/15\n",
            "train loss: 0.5971 --------------- train accuracy: 0.6925\n",
            "valid loss: 0.5931 --------------- valid accuracy: 0.6748\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 10/15\n",
            "train loss: 0.6029 --------------- train accuracy: 0.6904\n",
            "valid loss: 0.5963 --------------- valid accuracy: 0.6789\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 11/15\n",
            "train loss: 0.5937 --------------- train accuracy: 0.7026\n",
            "valid loss: 0.5941 --------------- valid accuracy: 0.6545\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 12/15\n",
            "train loss: 0.5943 --------------- train accuracy: 0.6904\n",
            "valid loss: 0.5944 --------------- valid accuracy: 0.6626\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 13/15\n",
            "train loss: 0.5894 --------------- train accuracy: 0.7067\n",
            "valid loss: 0.5927 --------------- valid accuracy: 0.6667\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 14/15\n",
            "train loss: 0.6001 --------------- train accuracy: 0.6701\n",
            "valid loss: 0.5915 --------------- valid accuracy: 0.6748\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 15/15\n",
            "train loss: 0.5880 --------------- train accuracy: 0.7067\n",
            "valid loss: 0.5941 --------------- valid accuracy: 0.6545\n",
            "--------------------------------------------------------------------------------\n",
            "Training completed in 18m 19s\n",
            "Best validation accuracy: 0.678862\n",
            "Loading final model weights...\n",
            "Fold 3/3\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 1/15\n",
            "train loss: 0.6451 --------------- train accuracy: 0.6321\n",
            "valid loss: 0.6859 --------------- valid accuracy: 0.5796\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 2/15\n",
            "train loss: 0.6500 --------------- train accuracy: 0.6016\n",
            "valid loss: 0.6517 --------------- valid accuracy: 0.6000\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 3/15\n",
            "train loss: 0.6536 --------------- train accuracy: 0.6077\n",
            "valid loss: 0.6429 --------------- valid accuracy: 0.6245\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 4/15\n",
            "train loss: 0.6470 --------------- train accuracy: 0.6077\n",
            "valid loss: 0.6374 --------------- valid accuracy: 0.6367\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 5/15\n",
            "train loss: 0.6368 --------------- train accuracy: 0.6402\n",
            "valid loss: 0.6340 --------------- valid accuracy: 0.6327\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 6/15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the model"
      ],
      "metadata": {
        "id": "0sUsorg-zKNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "torch.save(model.state_dict(), 'resnet50.pth')"
      ],
      "metadata": {
        "id": "0sQBavjx89oE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}