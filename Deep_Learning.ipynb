{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP1w8kqpYApofmQZBtwnKlF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmadJamal01/Floodead-Inside/blob/main/Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lU65wIk57haw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the dataset"
      ],
      "metadata": {
        "id": "aZmn6TyYyb2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdal > /dev/null"
      ],
      "metadata": {
        "id": "rArTdndiyA4z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "gdown.download(\"https://drive.google.com/uc?id=1och-QmNa3FAiS-wssgzCwISbmpSezIi_\", \"dataset.zip\", quiet=False)\n",
        "gdown.extractall(\"dataset.zip\")"
      ],
      "metadata": {
        "id": "a7XRy_rtyFEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the data"
      ],
      "metadata": {
        "id": "RgAykbJbytzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "path = 'dataset/'\n",
        "dataset = torchvision.datasets.ImageFolder(root=path, transform=data_transforms)\n",
        "\n",
        "# Split the dataset into train and test\n",
        "TRAIN_SIZE = 0.8\n",
        "train_size = int(TRAIN_SIZE * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = data.random_split(dataset, [train_size, test_size],generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "# Define the dataloaders\n",
        "train_loader = data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZevE8yKh8uDO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ],
      "metadata": {
        "id": "wpqTzs1Ry4ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define ResNet model \n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "#  Modify the first layer to be able to handle our data\n",
        "model.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "# Modify the last layer to work with two classes\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 2)\n",
        "\n",
        "# Move the model to GPU\n",
        "model.cuda()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "dRTZBJdo84PR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da2a23c-2372-49cf-8bc7-0fef044c1397"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 347MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "nLdO2X4OzB7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "num_epochs = 15\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if i % 10 == 9:\n",
        "            print('[Epoch %d, Batch %d] loss: %.3f' % (epoch+1, i+1, running_loss / 10))\n",
        "            running_loss = 0.0"
      ],
      "metadata": {
        "id": "hdjcLf-n854s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "954d73bc-8b57-4cef-ac2e-6e60482bb2ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Batch 10] loss: 0.644\n",
            "[Epoch 1, Batch 20] loss: 0.493\n",
            "[Epoch 2, Batch 10] loss: 0.382\n",
            "[Epoch 2, Batch 20] loss: 0.256\n",
            "[Epoch 3, Batch 10] loss: 0.222\n",
            "[Epoch 3, Batch 20] loss: 0.171\n",
            "[Epoch 4, Batch 10] loss: 0.204\n",
            "[Epoch 4, Batch 20] loss: 0.161\n",
            "[Epoch 5, Batch 10] loss: 0.091\n",
            "[Epoch 5, Batch 20] loss: 0.114\n",
            "[Epoch 6, Batch 10] loss: 0.155\n",
            "[Epoch 6, Batch 20] loss: 0.129\n",
            "[Epoch 7, Batch 10] loss: 0.095\n",
            "[Epoch 7, Batch 20] loss: 0.086\n",
            "[Epoch 8, Batch 10] loss: 0.067\n",
            "[Epoch 8, Batch 20] loss: 0.062\n",
            "[Epoch 9, Batch 10] loss: 0.059\n",
            "[Epoch 9, Batch 20] loss: 0.150\n",
            "[Epoch 10, Batch 10] loss: 0.091\n",
            "[Epoch 10, Batch 20] loss: 0.065\n",
            "[Epoch 11, Batch 10] loss: 0.109\n",
            "[Epoch 11, Batch 20] loss: 0.102\n",
            "[Epoch 12, Batch 10] loss: 0.036\n",
            "[Epoch 12, Batch 20] loss: 0.097\n",
            "[Epoch 13, Batch 10] loss: 0.066\n",
            "[Epoch 13, Batch 20] loss: 0.092\n",
            "[Epoch 14, Batch 10] loss: 0.082\n",
            "[Epoch 14, Batch 20] loss: 0.109\n",
            "[Epoch 15, Batch 10] loss: 0.123\n",
            "[Epoch 15, Batch 20] loss: 0.083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "Cxb3uKWfzHuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        # Move the inputs and labels to the GPU\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # Pass the inputs through the model to obtain the predicted outputs\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Select the class with the highest probability\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Convert the GPU tensors to CPU tensors and then to NumPy arrays to concatenate them with the existing y_true and y_pred lists\n",
        "        y_true += labels.cpu().numpy().tolist()\n",
        "        y_pred += predicted.cpu().numpy().tolist()\n",
        "\n",
        "# Calculate accuracy and F1 score\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
        "print('F1 Score: {:.2f}'.format(f1))"
      ],
      "metadata": {
        "id": "sWtfEoTz878B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb5d0ff-c73d-4a98-a257-eedec0feb5ba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 93.51%\n",
            "F1 Score: 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the model"
      ],
      "metadata": {
        "id": "0sUsorg-zKNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "torch.save(model.state_dict(), 'resnet18.pth')"
      ],
      "metadata": {
        "id": "0sQBavjx89oE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lFO2bINtyrzH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}