{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GLCM from skimage.feature\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "import os\n",
    "# PCA from sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "# train test split from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# lazy predict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "# brightness correction\n",
    "from skimage import exposure\n",
    "# HOG\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "# resize\n",
    "from skimage.transform import resize\n",
    "\n",
    "# score report\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patches(image, n = 10):\n",
    "    # width and height of the image\n",
    "    w, h = image.shape\n",
    "    # patch size = w/n, h/n\n",
    "    patches = []\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            patch = image[int(i*w/n):int((i+1)*w/n), int(j*h/n):int((j+1)*h/n)]\n",
    "            patches.append(patch)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glcm_properties(image, distances, angles, properties, n = 8):\n",
    "    w, h = image.shape\n",
    "\n",
    "    # make the image intensity to be integer from 0 to 255 instead of float from 0 to 1\n",
    "    image_int = (image*255).astype('uint8')\n",
    "\n",
    "    patches = get_patches(image_int, n)\n",
    "    # calculate the GLCM for each patch\n",
    "    glcm = [greycomatrix(patch, distances, angles, normed=True, symmetric=True) for patch in patches]\n",
    "\n",
    "    # calculate the properties for each patch\n",
    "    property_values = [np.hstack([greycoprops(g, prop).ravel() for prop in properties]) for g in glcm]\n",
    "\n",
    "    # make property_values a numpy array\n",
    "    property_values = np.array(property_values)\n",
    "\n",
    "    # flatten the array\n",
    "    property_values = property_values.flatten()\n",
    "\n",
    "    return property_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(image):\n",
    "    # brightness correction\n",
    "    image_corr = exposure.equalize_adapthist(image, clip_limit=0.03)\n",
    "\n",
    "    # scale image to 400x300\n",
    "    image_corr = resize(image_corr, (320, 400), anti_aliasing=True)\n",
    "\n",
    "    # HOG\n",
    "    fd= hog(image_corr, orientations=8, pixels_per_cell=(40, 50),\n",
    "                        cells_per_block=(1, 1), multichannel=False)\n",
    "\n",
    "    # GLCM\n",
    "    distances = [1, 3]\n",
    "    angles = [0, np.pi/4, np.pi/2]\n",
    "    properties = ['energy', 'homogeneity', 'contrast']\n",
    "\n",
    "    glcm = glcm_properties(image_corr, distances, angles, properties, n = 8)\n",
    "\n",
    "    # concatenate HOG and GLCM\n",
    "    features = np.concatenate((fd, glcm))\n",
    "\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_flattened_2 = []\n",
    "label_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, 461):\n",
    "    image = io.imread('flooded/'+str(i)+'.jpg', as_gray=True)\n",
    "    features = get_features(image)\n",
    "    features_flattened_2.append(features)\n",
    "    label_2.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(578, 1039):\n",
    "    image = io.imread('non-flooded/'+str(i)+'.jpg', as_gray=True)\n",
    "    features = get_features(image)\n",
    "    features_flattened_2.append(features)\n",
    "    label_2.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(922, 1664)\n"
     ]
    }
   ],
   "source": [
    "features_flattened_2_np = np.array(features_flattened_2)\n",
    "print(features_flattened_2_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(922, 1664)\n"
     ]
    }
   ],
   "source": [
    "features_np = np.reshape(features_flattened_2_np, (len(features_flattened_2), 1664))\n",
    "print(features_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(922,)\n"
     ]
    }
   ],
   "source": [
    "label_2_np = np.array(label_2)\n",
    "print(label_2_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save features and label to npy files\n",
    "np.save('features_2.npy', features_np)\n",
    "np.save('label_2.npy', label_2_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the features and labels\n",
    "indices = np.arange(len(label_2))\n",
    "np.random.shuffle(indices)\n",
    "features_np_shuffled = features_np[indices]\n",
    "label_np_shuffled = label_2_np[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_np_shuffled, label_np_shuffled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:33<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# lazy predict classifier\n",
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>8.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>6.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                         \n",
       "SVC                              0.92               0.92     0.92      0.92   \n",
       "NuSVC                            0.91               0.91     0.91      0.91   \n",
       "LGBMClassifier                   0.90               0.90     0.90      0.90   \n",
       "RandomForestClassifier           0.90               0.90     0.90      0.90   \n",
       "ExtraTreesClassifier             0.89               0.89     0.89      0.89   \n",
       "LogisticRegression               0.89               0.89     0.89      0.89   \n",
       "SGDClassifier                    0.88               0.88     0.88      0.88   \n",
       "XGBClassifier                    0.88               0.88     0.88      0.88   \n",
       "CalibratedClassifierCV           0.88               0.87     0.87      0.88   \n",
       "PassiveAggressiveClassifier      0.86               0.86     0.86      0.86   \n",
       "Perceptron                       0.85               0.85     0.85      0.85   \n",
       "LinearSVC                        0.85               0.85     0.85      0.85   \n",
       "AdaBoostClassifier               0.82               0.82     0.82      0.82   \n",
       "BaggingClassifier                0.81               0.80     0.80      0.81   \n",
       "DecisionTreeClassifier           0.77               0.77     0.77      0.77   \n",
       "LinearDiscriminantAnalysis       0.74               0.74     0.74      0.74   \n",
       "ExtraTreeClassifier              0.74               0.73     0.73      0.73   \n",
       "RidgeClassifierCV                0.74               0.73     0.73      0.73   \n",
       "KNeighborsClassifier             0.74               0.73     0.73      0.72   \n",
       "BernoulliNB                      0.73               0.73     0.73      0.73   \n",
       "\n",
       "                             Time Taken  \n",
       "Model                                    \n",
       "SVC                                0.45  \n",
       "NuSVC                              0.48  \n",
       "LGBMClassifier                     5.20  \n",
       "RandomForestClassifier             2.11  \n",
       "ExtraTreesClassifier               0.45  \n",
       "LogisticRegression                 0.20  \n",
       "SGDClassifier                      0.13  \n",
       "XGBClassifier                      3.18  \n",
       "CalibratedClassifierCV             1.99  \n",
       "PassiveAggressiveClassifier        0.18  \n",
       "Perceptron                         0.11  \n",
       "LinearSVC                          0.91  \n",
       "AdaBoostClassifier                 8.08  \n",
       "BaggingClassifier                  6.19  \n",
       "DecisionTreeClassifier             0.79  \n",
       "LinearDiscriminantAnalysis         1.01  \n",
       "ExtraTreeClassifier                0.09  \n",
       "RidgeClassifierCV                  0.36  \n",
       "KNeighborsClassifier               0.10  \n",
       "BernoulliNB                        0.10  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "# LGBMClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# grid search for SVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# hard voting of classifiers\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "# logistic regression for classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# SGDClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# XGBClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82        95\n",
      "           1       0.83      0.77      0.80        90\n",
      "\n",
      "    accuracy                           0.81       185\n",
      "   macro avg       0.81      0.81      0.81       185\n",
      "weighted avg       0.81      0.81      0.81       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train SVC classifier \n",
    "\n",
    "clf = SVC(kernel='rbf', C=10, gamma=\"scale\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        95\n",
      "           1       0.90      0.91      0.91        90\n",
      "\n",
      "    accuracy                           0.91       185\n",
      "   macro avg       0.91      0.91      0.91       185\n",
      "weighted avg       0.91      0.91      0.91       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        95\n",
      "           1       0.89      0.93      0.91        90\n",
      "\n",
      "    accuracy                           0.91       185\n",
      "   macro avg       0.91      0.91      0.91       185\n",
      "weighted avg       0.91      0.91      0.91       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_et = ExtraTreesClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "clf_et.fit(X_train, y_train)\n",
    "\n",
    "# predict the test set\n",
    "y_pred = clf_et.predict(X_test)\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        95\n",
      "           1       0.89      0.92      0.91        90\n",
      "\n",
      "    accuracy                           0.91       185\n",
      "   macro avg       0.91      0.91      0.91       185\n",
      "weighted avg       0.91      0.91      0.91       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LGBMClassifier\n",
    "clf = LGBMClassifier(max_depth=10, n_estimators=200, learning_rate=0.2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84        95\n",
      "           1       0.83      0.84      0.84        90\n",
      "\n",
      "    accuracy                           0.84       185\n",
      "   macro avg       0.84      0.84      0.84       185\n",
      "weighted avg       0.84      0.84      0.84       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NU SVC\n",
    "clf = NuSVC(nu=0.01, kernel='rbf', gamma='scale')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71        95\n",
      "           1       0.69      0.73      0.71        90\n",
      "\n",
      "    accuracy                           0.71       185\n",
      "   macro avg       0.71      0.71      0.71       185\n",
      "weighted avg       0.71      0.71      0.71       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SGDClassifier\n",
    "clf = SGDClassifier(loss=\"log_loss\", penalty=\"elasticnet\", random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89        95\n",
      "           1       0.87      0.90      0.89        90\n",
      "\n",
      "    accuracy                           0.89       185\n",
      "   macro avg       0.89      0.89      0.89       185\n",
      "weighted avg       0.89      0.89      0.89       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBClassifier\n",
    "clf = XGBClassifier(max_depth=10, n_estimators=100, learning_rate=0.1, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.92        95\n",
      "           1       0.90      0.94      0.92        90\n",
      "\n",
      "    accuracy                           0.92       185\n",
      "   macro avg       0.92      0.92      0.92       185\n",
      "weighted avg       0.93      0.92      0.92       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#VotingClassifier\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=0)\n",
    "clf_et = ExtraTreesClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "clf_lgbm = LGBMClassifier(max_depth=10, n_estimators=200, learning_rate=0.2, random_state=0)\n",
    "\n",
    "clf = VotingClassifier(estimators=[('rf', clf_rf), ('et', clf_et), ('lgbm', clf_lgbm)], voting='hard')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9245614035087719\n"
     ]
    }
   ],
   "source": [
    "# get parameters for the best "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
