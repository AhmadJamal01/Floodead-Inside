{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvOR45vzVsbNpOmoR7vA9O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmadJamal01/Floodead-Inside/blob/main/Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "y5MJDPraBa1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.svm import SVC\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from osgeo import gdal\n",
        "import cv2\n",
        "from skimage.feature import hog\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "NUM_FOLDS = 10"
      ],
      "metadata": {
        "id": "kw4xbu2jBd7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the Data"
      ],
      "metadata": {
        "id": "goyobUkSBeL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdal > /dev/null"
      ],
      "metadata": {
        "id": "6KG9CuAVBhSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "gdown.download(\"https://drive.google.com/uc?id=1och-QmNa3FAiS-wssgzCwISbmpSezIi_\", \"dataset.zip\", quiet=False)\n",
        "gdown.extractall(\"dataset.zip\")\n",
        "path = 'dataset/'\n"
      ],
      "metadata": {
        "id": "qD-f2mNYCCh7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "1fa8a686-1910-4969-a2b2-86c20f2e4e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/file/d/1och-QmNa3FAiS-wssgzCwISbmpSezIi_\n",
            "To: /content/dataset.zip\n",
            "75.5kB [00:00, 34.8MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-faaca7f15d75>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgdown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://drive.google.com/file/d/1och-QmNa3FAiS-wssgzCwISbmpSezIi_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dataset.zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dataset/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m'https://drive.google.com/file/d/1och-QmNa3FAiS-wssgzCwISbmpSezIi_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gdown/extractall.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(path, to)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the Data"
      ],
      "metadata": {
        "id": "qxliIRA3CinH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns=['image_path', 'label'])\n",
        "\n",
        "for image_path in sorted(glob.glob('dataset/flooded/*.jpg')):\n",
        "    data = {'image_path': image_path, 'label': 'flooded'}\n",
        "    df.loc[len(df)] = data\n",
        "\n",
        "for image_path in sorted(glob.glob('dataset/non-flooded/*.jpg')):\n",
        "    data = {'image_path': image_path, 'label': 'non-flooded'}\n",
        "    df.loc[len(df)] = data"
      ],
      "metadata": {
        "id": "AVhfujkICFwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "print(\"Dataset shape:\", df.shape)"
      ],
      "metadata": {
        "id": "-jutcFdXDfy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract Features"
      ],
      "metadata": {
        "id": "enX9T1eZDa0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HOG"
      ],
      "metadata": {
        "id": "3dMUi9k3PXaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_hog_features(image):\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    hog_features = hog(gray_image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2))\n",
        "    return hog_features\n"
      ],
      "metadata": {
        "id": "KqyTXjDFDMQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Color-based Features"
      ],
      "metadata": {
        "id": "etgezdH_PZaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def calculate_average_color(image):\n",
        "    average_color = np.mean(image, axis=(0, 1))\n",
        "    return average_color\n",
        "\n",
        "def calculate_color_histogram(image):\n",
        "    hist = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
        "    hist = cv2.normalize(hist, hist).flatten()\n",
        "    return hist\n"
      ],
      "metadata": {
        "id": "wVhSHBubPgxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Texture-based Features"
      ],
      "metadata": {
        "id": "6HNQvRrGPpR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.feature import greycomatrix, graycoprops\n",
        "from skimage.feature import local_binary_pattern\n",
        "\n",
        "\n",
        "# Gray-Level Co-occurrence Matrix (GLCM): Computes the distribution of co-occurring pixel values in different directions.\n",
        "def calculate_glcm_features(image):\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # glcm = greycomatrix(gray_image, [1], [0], 256, symmetric=True, normed=True)\n",
        "    # contrast = greycoprops(glcm, 'contrast')[0, 0]\n",
        "    # correlation = greycoprops(glcm, 'correlation')[0, 0]\n",
        "    # energy = greycoprops(glcm, 'energy')[0, 0]\n",
        "    # homogeneity = greycoprops(glcm, 'homogeneity')[0, 0]\n",
        "    # return contrast, correlation, energy, homogeneity\n",
        "    glcm = greycomatrix(gray_image, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4], levels=256, normed=True, symmetric=True)\n",
        "    return graycoprops(glcm, 'contrast').mean(), graycoprops(glcm, 'correlation').mean(), graycoprops(glcm, 'energy').mean(), graycoprops(glcm, 'homogeneity').mean(), graycoprops(glcm, 'dissimilarity').mean()\n",
        "\n",
        "# Local Binary Patterns (LBP): Captures the patterns in the texture of the image.\n",
        "def calculate_lbp_features(image):\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    lbp = local_binary_pattern(gray_image, 8, 1, method='uniform')\n",
        "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 10), range=(0, 10))\n",
        "    hist = hist.astype(\"float\")\n",
        "    hist /= (hist.sum() + 1e-7)\n",
        "    return hist\n"
      ],
      "metadata": {
        "id": "gO1_oPK4Puj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shape-based Features"
      ],
      "metadata": {
        "id": "yv3NWPDmP5Mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_contour_area(image):\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contour_area = 0\n",
        "    for contour in contours:\n",
        "        contour_area += cv2.contourArea(contour)\n",
        "    return contour_area\n",
        "\n",
        "def calculate_aspect_ratio(image):\n",
        "    height, width, _ = image.shape\n",
        "    aspect_ratio = width / height\n",
        "    return aspect_ratio\n"
      ],
      "metadata": {
        "id": "xR4EkKXPP7dB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract"
      ],
      "metadata": {
        "id": "O4B8DA_kPlM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take only a portion of the dataframe\n",
        "newLen = 50\n",
        "X_sampled = df.sample(n=newLen, random_state=42)\n",
        "\n",
        "# Drop the remaining rows\n",
        "X_dropped = df.drop(X_sampled.index)\n",
        "\n",
        "# Verify the shapes of the dataframes\n",
        "print(\"Sampled Data Shape:\", X_sampled.shape)\n",
        "print(\"Dropped Data Shape:\", X_dropped.shape)"
      ],
      "metadata": {
        "id": "T7oRhvaDdHst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# Initialize lists to store features and target labels\n",
        "features = []\n",
        "targets = []\n",
        "\n",
        "i = 0\n",
        "# Iterate over the images in the directory\n",
        "for index, row in df.iterrows():\n",
        "        image_path = row['image_path']\n",
        "        image = cv2.imread(image_path)\n",
        "        \n",
        "        # Extract the features from the image\n",
        "        hog_features = calculate_hog_features(image)\n",
        "        # average_color = calculate_average_color(image)\n",
        "        # color_histogram = calculate_color_histogram(image)\n",
        "        # glcm_features = calculate_glcm_features(image)\n",
        "        # lbp_features = calculate_lbp_features(image)\n",
        "        # contour_area = calculate_contour_area(image)\n",
        "        # aspect_ratio = calculate_aspect_ratio(image)\n",
        "        \n",
        "        # Append the features to the list\n",
        "        # feature_row = [*hog_features, *average_color, *color_histogram, *glcm_features, *lbp_features, contour_area, aspect_ratio]\n",
        "        feature_row = [*hog_features]\n",
        "        features.append(feature_row)\n",
        "        \n",
        "        # Determine the target class based on the folder name\n",
        "        label = row['label']\n",
        "        if 'flooded' == label:\n",
        "            target = 1\n",
        "        elif 'non-flooded' == label:\n",
        "            target = -1\n",
        "        else:\n",
        "            target = 0\n",
        "        \n",
        "        # Append the target label to the list\n",
        "        targets.append(target)\n",
        "        print(i); i=i+1\n",
        "\n"
      ],
      "metadata": {
        "id": "biI5BbGgYbXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the X dataframe with features\n",
        "X_columns = ['hog_features', 'average_color', 'color_histogram', 'glcm_features', 'lbp_features', 'contour_area', 'aspect_ratio']\n",
        "X = pd.DataFrame(features, columns=X_columns)\n",
        "\n",
        "# Create the y dataframe with target labels and drop the 'target' column from X\n",
        "y = pd.DataFrame(targets, columns=['target'])\n",
        "X.drop('target', axis=1, inplace=True)\n",
        "\n",
        "# Scale the numerical features in X using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = pd.DataFrame(scaler.fit_transform(X), columns=X_columns)\n"
      ],
      "metadata": {
        "id": "lkBdAAKgaE9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the Data"
      ],
      "metadata": {
        "id": "PGSOOOTlInnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "HDUvs7GYIoMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "cE8G4p91Ix8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = LinearSVC()\n",
        "svm.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "tstIDb3pIzVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "8RLxVCXWI1tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svm.predict(X_test)\n"
      ],
      "metadata": {
        "id": "niAyvUTSI5FI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n"
      ],
      "metadata": {
        "id": "5fPoY-Z-I5n1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}